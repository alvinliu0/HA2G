name: hierarchy

train_data_path: /mnt/lustressd/share/liuxian.vendor/ted_dataset/lmdb_train
val_data_path: /mnt/lustressd/share/liuxian.vendor/ted_dataset/lmdb_val
test_data_path: /mnt/lustressd/share/liuxian.vendor/ted_dataset/lmdb_test

wordembed_dim: 300
wordembed_path: data/fasttext/crawl-300d-2M-subword.bin  # from https://fasttext.cc/docs/en/english-vectors.html
#freeze_wordembed: true

model_save_path: TED-Gesture-output/train_hierarchy
random_seed: -1

# model params
model: hierarchy
mean_dir_vec: [ 0.0154009, -0.9690125, -0.0884354, -0.0022264, -0.8655276, 0.4342174, -0.0035145, -0.8755367, -0.4121039, -0.9236511, 0.3061306, -0.0012415, -0.5155854,  0.8129665,  0.0871897, 0.2348464,  0.1846561,  0.8091402,  0.9271948,  0.2960011, -0.013189 ,  0.5233978,  0.8092403,  0.0725451, -0.2037076, 0.1924306,  0.8196916]
mean_pose: [ 0.0000306,  0.0004946,  0.0008437,  0.0033759, -0.2051629, -0.0143453,  0.0031566, -0.3054764,  0.0411491,  0.0029072, -0.4254303, -0.001311 , -0.1458413, -0.1505532, -0.0138192, -0.2835603,  0.0670333,  0.0107002, -0.2280813,  0.112117 , 0.2087789,  0.1523502, -0.1521499, -0.0161503,  0.291909 , 0.0644232,  0.0040145,  0.2452035,  0.1115339,  0.2051307]

n_layers: 4
hidden_size: 300
z_type: speaker  # speaker, random, none
input_context: both  # both, audio, text, none

# train params
epochs: 100
batch_size: 256
learning_rate: 5e-4
loss_regression_weight: 70.0
loss_gan_weight: 5.0
loss_warmup: 10
loss_kld_weight: 0.1
loss_reg_weight: 0.05

loss_contrastive_pos_weight: 0.2
loss_contrastive_neg_weight: 0.005
loss_physical_weight: 0.01

# eval params
eval_net_path: data/train_h36m_gesture_autoencoder_gesture_autoencoder_checkpoint_best.bin

# dataset params
motion_resampling_framerate: 15
n_poses: 34
n_pre_poses: 4
subdivision_stride: 10
loader_workers: 8

pose_dim: 27